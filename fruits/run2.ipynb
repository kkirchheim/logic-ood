{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e68aaa-4b3b-46f8-a9bb-df16e1bd6e7a",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, random_split\n",
    "import os \n",
    "from os.path import join \n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import sys\n",
    "logger = logging.getLogger()\n",
    "logger.addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.info(\"abc\")\n",
    "\n",
    "device = \"cuda:0\"\n",
    "root = \"/home/ki/datasets/\"\n",
    "\n",
    "from detector import label_to_name, color_to_name\n",
    "\n",
    "class FruitDataset(Dataset):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    class_color_map = {\n",
    "        \"Apple Braeburn\": \"red\",\n",
    "        \"Apple Granny Smith\": \"green\",\n",
    "        \"Apricot\": \"orange\",\n",
    "        \"Avocado\": \"green\",\n",
    "        \"Banana\": \"yellow\",\n",
    "        \"Blueberry\": \"black\",\n",
    "        \"Cactus fruit\": \"green\",\n",
    "        \"Cantaloupe\": \"yellow\",\n",
    "        \"Cherry\": \"red\",\n",
    "        \"Clementine\": \"orange\",\n",
    "        \"Corn\": \"yellow\",\n",
    "        \"Cucumber Ripe\": \"brown\",\n",
    "        \"Grape Blue\": \"black\",\n",
    "        \"Kiwi\": \"brown\",\n",
    "        \"Lemon\": \"yellow\",\n",
    "        \"Limes\": \"green\",\n",
    "        \"Mango\": \"green\",\n",
    "        \"Onion White\": \"brown\",\n",
    "        \"Orange\": \"orange\",\n",
    "        \"Papaya\": \"green\",\n",
    "        \"Passion Fruit\": \"black\",\n",
    "        \"Peach\": \"orange\",\n",
    "        \"Pear\": \"green\", # ??\n",
    "        \"Pepper Green\": \"green\",\n",
    "        \"Pepper Red\": \"red\",\n",
    "        \"Pineapple\": \"brown\",\n",
    "        \"Plum\": \"red\",\n",
    "        \"Pomegranate\": \"red\",\n",
    "        \"Potato Red\": \"brown\",\n",
    "        \"Raspberry\": \"red\",\n",
    "        \"Strawberry\": \"red\",\n",
    "        \"Tomato\": \"red\",\n",
    "        \"Watermelon\": \"red\" \n",
    "    }\n",
    "    \n",
    "    def __init__(self, root=\"train\", transform=None, target_transform=None):\n",
    "        root = join(root, \"fruits\", \"train\", \"train\")\n",
    "\n",
    "        self.classes = os.listdir(root)\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.colors = []\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform \n",
    "        \n",
    "        for c in self.classes:\n",
    "            fs = [join(root, c, f) for f in os.listdir(join(root, c))]\n",
    "            self.files += fs\n",
    "            self.labels += [c.lower().replace(\" \", \"_\")] * len(fs)\n",
    "            self.colors += [self.class_color_map[c]] * len(fs)\n",
    "\n",
    "        self.class_map = {c: n for n, c in enumerate(label_to_name)}\n",
    "        self.color_map = {c: n for n, c in enumerate(color_to_name)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.files[index]\n",
    "        y = self.class_map[self.labels[index]]\n",
    "        color = self.color_map[self.colors[index]]\n",
    "        \n",
    "        img = Image.open(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        y = torch.tensor([y, color]) \n",
    "        if self.target_transform is not None:\n",
    "            y = self.target_transform(y)\n",
    "        \n",
    "        return img, y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c8d208-b5cc-40cd-95d1-984635599b8b",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "ds = FruitDataset(root=root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e713eb-873e-4c92-b9a5-6d5d3a069707",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from pytorch_ood.utils import ToRGB\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "trans = Compose([ToRGB(), ToTensor(), Resize((32, 32), antialias=True)])\n",
    "\n",
    "data = FruitDataset(root=root, transform=trans)\n",
    "train_data, val_data, test_data = random_split(data, [14000,1000, 1854], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f40b8b-621b-47cd-bf1a-2ad43081edf8",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from pytorch_ood.model import WideResNet\n",
    "\n",
    "# def override \n",
    "def Model(num_classes=None, *args, **kwargs):\n",
    "    model = WideResNet(*args, num_classes=1000, pretrained=\"imagenet32\", **kwargs)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd36c49f-3254-4808-a751-1c79b5c0d4a3",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "\n",
    "def train_model(att_index, num_classes):\n",
    "    \"\"\"\n",
    "    train a model for the given attribute index \n",
    "    \"\"\"\n",
    "    model = Model(num_classes=num_classes).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        bar = tqdm(train_loader)\n",
    "        for inputs, y in bar:\n",
    "            labels = y[:, att_index]\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss = 0.8 * running_loss + 0.2 * loss.item()\n",
    "            bar.set_postfix({\"loss\": running_loss})\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            for inputs, y in test_loader:\n",
    "                labels = y[:, att_index]\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, dim=1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Accuracy of the network on the test images: {correct / total:.2%}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pytorch_ood.dataset.img import TinyImages300k\n",
    "from pytorch_ood.utils import is_known\n",
    "\n",
    "def train_fruit_model():\n",
    "    tiny = TinyImages300k(root=root, download=True, transform=trans, target_transform=ToUnknown())\n",
    "    data_train_out, data_test_out, _ = random_split(tiny, [50000, 10000, 240000], generator=torch.Generator().manual_seed(123))\n",
    "\n",
    "    data_noatt = FruitDataset(root=root, transform=trans, target_transform=lambda y: int(y[0]))\n",
    "    train_data_noatt, val_data_noatt, test_data_noatt = random_split(data_noatt, [14000,1000, 1854], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "    new_loader = DataLoader(train_data_noatt + data_train_out, batch_size=32, shuffle=True, num_workers=10)\n",
    "    new_test_loader = DataLoader(test_data_noatt + data_test_out, batch_size=32, shuffle=False, num_workers=10)\n",
    "\n",
    "    model = Model(num_classes=2).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "    accs = []\n",
    "\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "\n",
    "        bar = tqdm(new_loader)\n",
    "        for inputs, y in bar:\n",
    "            labels = is_known(y).long()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss = 0.8 * running_loss + 0.2 * loss.item()\n",
    "            bar.set_postfix({\"loss\": running_loss})\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            for inputs, y in new_test_loader:\n",
    "                labels = is_known(y).long()\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Accuracy of the shape network on the test images: {correct / total:.2%}')\n",
    "        accs.append(correct / total)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a02580-6d2c-4db2-a4b7-50c8dbbabf22",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from pytorch_ood.dataset.img import (LSUNCrop, LSUNResize, Textures, TinyImageNetCrop, TinyImageNetResize)\n",
    "from pytorch_ood.detector import EnergyBased, MaxSoftmax, MaxLogit, Entropy, Mahalanobis, ViM, ReAct\n",
    "from pytorch_ood.utils import OODMetrics, ToUnknown\n",
    "from detector import EnsembleDetector, PrologOOD, Prologic, PrologOODT\n",
    "\n",
    "def evaluate(label_net, color_net, fruit_net):\n",
    "    _ = label_net.eval()\n",
    "    _ = color_net.eval()\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    detectors = {\n",
    "        \"ViM\": ViM(label_net.features, w=label_net.fc.weight, b=label_net.fc.bias, d=64),\n",
    "        \"Mahalanobis\": Mahalanobis(label_net.features),\n",
    "        \"Entropy\": Entropy(label_net),\n",
    "        \"LogicOOD+\": PrologOOD(\"kb.pl\", label_net, color_net, fruit_net),\n",
    "        \"Logic\": Prologic(\"kb.pl\", label_net, color_net),\n",
    "        \"Logic+\": Prologic(\"kb.pl\", label_net, color_net, fruit_net),\n",
    "        \"LogicOOD\": PrologOOD(\"kb.pl\", label_net, color_net),\n",
    "        \"LogicOODT\": PrologOODT(\"kb.pl\", label_net, color_net),\n",
    "        \"LogicOODT+\": PrologOODT(\"kb.pl\", label_net, color_net, fruit_net),\n",
    "        # \"LogicT+\": PrologOODT(\"kb.pl\", label_net, color_net, fruit_net), # this should be exactly the same\n",
    "        \"Ensemble\": EnsembleDetector(label_net, color_net),\n",
    "        \"MSP\": MaxSoftmax(label_net),\n",
    "        \"ReAct\": ReAct(label_net.features, label_net.fc),\n",
    "        \"Energy\": EnergyBased(label_net),\n",
    "        \"MaxLogit\": MaxLogit(label_net),\n",
    "    }\n",
    "\n",
    "\n",
    "    data_fit_label = FruitDataset(root=root, transform=trans,  target_transform=lambda y: torch.tensor(y[0]))\n",
    "    _ , data_fit_label, _ = random_split(data_fit_label, [14000, 1000, 1854], generator=torch.Generator().manual_seed(0))\n",
    "    data_fit_color = FruitDataset(root=root, transform=trans,  target_transform=lambda y: torch.tensor(y[1]))\n",
    "    _, data_fit_color, _ = random_split(data_fit_color, [14000, 1000, 1854], generator=torch.Generator().manual_seed(0))\n",
    "    data_fit_color = DataLoader(data_fit_color, batch_size=32, shuffle=False, num_workers=2)\n",
    "    data_fit_label = DataLoader(data_fit_label, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "    data = FruitDataset(root=root, transform=trans, target_transform=lambda y: int(y[0]))\n",
    "    data_in_train, data_in_val, data_in = random_split(data, [14000, 1000, 1854], generator=torch.Generator().manual_seed(0))\n",
    "    train_in_loader = DataLoader(data_in_train, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "    detectors[\"ViM\"].fit(train_in_loader, device=device)\n",
    "    detectors[\"LogicOODT\"].fit(data_fit_label, data_fit_color, device=device)\n",
    "    detectors[\"LogicOODT+\"].fit(data_fit_label, data_fit_color, device=device)\n",
    "    detectors[\"Mahalanobis\"].fit(train_in_loader, device=device)\n",
    "\n",
    "    datasets = {d.__name__: d for d in (LSUNCrop, LSUNResize, Textures, TinyImageNetCrop, TinyImageNetResize)}\n",
    "    \n",
    "    for detector_name, detector in detectors.items():\n",
    "        for data_name, dataset_c in datasets.items():\n",
    "            print(data_name)\n",
    "            data_out = dataset_c(root=root, transform=trans, target_transform=ToUnknown(), download=True)\n",
    "            loader = DataLoader(data_in+data_out, batch_size=256, shuffle=False, num_workers=12)\n",
    "            \n",
    "            scores = []\n",
    "            ys = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for x, y in loader:\n",
    "                    scores.append(detector(x.to(device)))\n",
    "                    ys.append(y.to(device))\n",
    "                    \n",
    "                scores = torch.cat(scores, dim=0).cpu()\n",
    "                ys = torch.cat(ys, dim=0).cpu()\n",
    "            \n",
    "            metrics = OODMetrics()\n",
    "            metrics.update(scores, ys)\n",
    "            r = metrics.compute()\n",
    "            r.update({\n",
    "                \"Method\": detector_name,\n",
    "                \"Dataset\": data_name\n",
    "            })\n",
    "            print(r)\n",
    "            results.append(r)\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a358f-c6ef-4fe9-9b1a-c305a37ffb70",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for trial in range(10):\n",
    "    print(\"label\")\n",
    "    label_net = train_model(att_index=0, num_classes=33)\n",
    "    print(\"color\")\n",
    "    color_net = train_model(att_index=1, num_classes=6)\n",
    "    print(\"fruit\")\n",
    "\n",
    "    fruit_net = train_fruit_model()\n",
    "\n",
    "    res = evaluate(label_net, color_net, fruit_net)\n",
    "    \n",
    "    for r in res:\n",
    "        r.update({\"Seed\": trial})\n",
    "    \n",
    "    results += res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5287e-1bd0-4bfd-a73f-e427f369f3c2",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result_df = pd.DataFrame(results)\n",
    "# print((result_df.groupby(by=\"Method\").agg([\"mean\", \"sem\"]) * 100)[[\"AUROC\", \"AUPR-IN\", \"AUPR-OUT\", \"FPR95TPR\"]].to_latex(float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# s = (result_df.groupby(by=\"Method\").agg([\"mean\", \"sem\"]) * 100)[[\"AUROC\", \"AUPR-IN\", \"AUPR-OUT\", \"FPR95TPR\"]].to_latex(float_format=\"%.2f\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "order = ['MSP', 'Energy', 'MaxLogit', 'Entropy', 'ReAct', 'Mahalanobis', 'ViM', 'Ensemble', 'Logic', 'Logic+', 'LogicOOD', 'LogicOOD+', 'LogicOODT', 'LogicOODT+']\n",
    "\n",
    "\n",
    "print((result_df.groupby(by=[\"Method\", \"Seed\"]).mean() * 100).groupby(\"Method\").agg([\"mean\", \"sem\"]).reindex(order).to_latex(float_format=\"%.2f\").replace(\"& 0.\", \"& $\\pm$ 0.\").replace(\"& 2.\", \"& $\\pm$ 2.\").replace(\"& 3.\", \"& $\\pm$ 3.\").replace(\"& 1.\", \"& $\\pm$ 1.\").replace(\"& 4.\", \"& $\\pm$ 4.\").replace(\"& 5.\", \"& $\\pm$ 5.\"))\n",
    "\n",
    "\n",
    "# print(s.replace(\"& 0.\", \"& \\pm 0.\").replace(\"& 1.\", \"& \\pm 1.\").replace(\"& 2.\", \"& \\pm 2.\").replace(\"& 4.\", \"& \\pm 4.\"))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
