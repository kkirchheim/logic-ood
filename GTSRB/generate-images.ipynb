{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af862375",
   "metadata": {},
   "source": [
    "# Street sign with Pre-Trained WideResNet\n",
    "\n",
    "With additional shield net, generate example images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7047f3bd-ed5b-45e4-b738-f0b3422677cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/.local/share/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343964576/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e8ccc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6e1cdd0810>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from os.path import join\n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "from torch.optim import SGD\n",
    "import seaborn as sb \n",
    "from gtsrb import GTSRB\n",
    "from detectors import EnsembleDetector, SemanticDetector, LogicOnlyDetector\n",
    "import os \n",
    "from pytorch_ood.utils import fix_random_seed\n",
    "import seaborn as sb \n",
    "import torch \n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"MIG-GPU-bb1ccb6e-2bc9-c7a1-b25d-3eef9033e192/0/0\" \n",
    "\n",
    "sb.set()\n",
    "\n",
    "device=\"cuda:0\"\n",
    "root = \"../data/\"\n",
    "\n",
    "\n",
    "fix_random_seed()\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    fix_random_seed()\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd741f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trans = Compose([ToTensor(), Resize((32, 32))])\n",
    "\n",
    "train_data = GTSRB(root=root, train=True, transforms=trans)\n",
    "test_data = GTSRB(root=root, train=False, transforms=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7226cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2, worker_init_fn=seed_worker)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=2, worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31d837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision.models.resnet import resnet18\n",
    "from pytorch_ood.model import WideResNet\n",
    "from functools import partial\n",
    "\n",
    "# def override \n",
    "def Model(num_classes=None, *args, **kwargs):\n",
    "    model = WideResNet(*args, num_classes=1000, **kwargs, pretrained=\"imagenet32\")\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fae44395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm \n",
    "import numpy as np \n",
    "\n",
    "def train_model(att_index, num_classes, n_epochs=20):\n",
    "    \"\"\"\n",
    "    train a model for the given attribute index \n",
    "    \"\"\"\n",
    "    trans = Compose([ToTensor(), Resize((32, 32))])\n",
    "    train_data = GTSRB(root=root, train=True, transforms=trans)\n",
    "    test_data = GTSRB(root=root, train=False, transforms=trans)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2, worker_init_fn=seed_worker)\n",
    "    test_loader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=2, worker_init_fn=seed_worker)\n",
    "    \n",
    "    model = Model(num_classes=num_classes).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "    accs = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        bar = tqdm(train_loader)\n",
    "        for inputs, y in bar:\n",
    "            labels = y[:, att_index]\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss = 0.8 * running_loss + 0.2 * loss.item()\n",
    "            bar.set_postfix({\"loss\": running_loss})\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            for inputs, y in test_loader:\n",
    "                labels = y[:, att_index]\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, dim=1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Accuracy of the network on the test images: {correct / total:.2%}')\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8074726",
   "metadata": {},
   "source": [
    "# Sign Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc36a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from pytorch_ood.utils import is_known\n",
    "from tqdm.notebook import tqdm \n",
    "from pytorch_ood.dataset.img import TinyImages300k\n",
    "from pytorch_ood.utils import ToUnknown\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "def train_sign_model(n_epochs=20):\n",
    "    tiny = TinyImages300k(root=root, download=True, transform=trans, target_transform=ToUnknown())\n",
    "    data_train_out, data_test_out, _ = random_split(tiny, [50000, 10000, 240000], generator=torch.Generator().manual_seed(123))\n",
    "\n",
    "    train_data_noatt = GTSRB(root=root, train=True, transforms=trans, target_transform=lambda y: y[0])\n",
    "    test_data_noatt = GTSRB(root=root, train=False, transforms=trans, target_transform=lambda y: y[0])\n",
    "\n",
    "    new_loader = DataLoader(train_data_noatt + data_train_out, batch_size=32, shuffle=True, num_workers=10, worker_init_fn=seed_worker)\n",
    "    new_test_loader = DataLoader(test_data_noatt + data_test_out, batch_size=32, shuffle=False, num_workers=10, worker_init_fn=seed_worker)\n",
    "\n",
    "    model = Model(num_classes=2).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "    accs = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        bar = tqdm(new_loader)\n",
    "        for inputs, y in bar:\n",
    "            labels = is_known(y).long()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss = 0.8 * running_loss + 0.2 * loss.item()\n",
    "            bar.set_postfix({\"loss\": running_loss})\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            for inputs, y in new_test_loader:\n",
    "                labels = is_known(y).long()\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Accuracy of the shape network on the test images: {correct / total:.2%}')\n",
    "        accs.append(correct / total)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a026c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OOD Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74bae9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_ood.dataset.img import (LSUNCrop, LSUNResize, Textures, TinyImageNetCrop, TinyImageNetResize)\n",
    "from pytorch_ood.detector import EnergyBased, MaxSoftmax, Mahalanobis, MaxLogit, ViM, Entropy\n",
    "from pytorch_ood.utils import ToRGB, OODMetrics\n",
    "\n",
    "def evaluate(label_net, shape_net, color_net, shield_net):\n",
    "    _ = label_net.eval()\n",
    "    _ = shape_net.eval()\n",
    "    _ = color_net.eval()\n",
    "    _ = shield_net.eval()\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    trans = Compose([Resize(size=(32, 32)), ToRGB(), ToTensor()])\n",
    "    data_in = GTSRB(root=root, train=False, transforms=trans, target_transform=lambda y: y[0])\n",
    "    data_in_train = GTSRB(root=root, train=True, transforms=trans, target_transform=lambda y: y[0])\n",
    "    loader_train = DataLoader(data_in_train, batch_size=1024, shuffle=False, worker_init_fn=seed_worker)\n",
    "    # dataset_out_test = Textures(root=root, transform=trans, target_transform=ToUnknown(), download=True)\n",
    "    \n",
    "    \n",
    "    detectors = {\n",
    "        \"MSP\": MaxSoftmax(label_net),\n",
    "        \"Energy\": EnergyBased(label_net),\n",
    "        \"Mahalanobis\": Mahalanobis(label_net.features),\n",
    "        \"MaxLogit\": MaxLogit(label_net),\n",
    "        \"Entropy\": Entropy(label_net),\n",
    "        \"ViM\": ViM(label_net.features, w=label_net.fc.weight, b=label_net.fc.bias, d=64),\n",
    "        \"Logic\": LogicOnlyDetector(\n",
    "            label_net, shape_net, \n",
    "            color_net, \n",
    "            GTSRB(root=root).class_to_shape, \n",
    "            GTSRB(root=root).class_to_color\n",
    "        ),\n",
    "        \"Logic+\": LogicOnlyDetector(\n",
    "            label_net, shape_net, \n",
    "            color_net, \n",
    "            GTSRB(root=root).class_to_shape, \n",
    "            GTSRB(root=root).class_to_color,\n",
    "            sign_net=shield_net,\n",
    "        ),\n",
    "        \"LogicOOD+\": SemanticDetector(\n",
    "            label_net, \n",
    "            shape_net, \n",
    "            color_net, \n",
    "            GTSRB(root=root).class_to_shape, \n",
    "            GTSRB(root=root).class_to_color, \n",
    "            sign_net=shield_net\n",
    "        ),\n",
    "        \"LogicOOD\": SemanticDetector(\n",
    "                label_net, \n",
    "                shape_net, \n",
    "                color_net, \n",
    "                GTSRB(root=root).class_to_shape, \n",
    "                GTSRB(root=root).class_to_color, \n",
    "        ),\n",
    "        \"Ensemble\": EnsembleDetector(label_net, shape_net, color_net)\n",
    "    }\n",
    "    \n",
    "    for detector_name, detector in detectors.items():\n",
    "        print(f\"Fitting {detector_name}\")\n",
    "        try:\n",
    "            detector.fit(loader_train, device=device)\n",
    "        except TypeError:\n",
    "            detector.fit(loader_train)\n",
    "        \n",
    "    datasets = {d.__name__: d for d in (LSUNCrop, LSUNResize, Textures, TinyImageNetCrop, TinyImageNetResize)}\n",
    "    \n",
    "    for detector_name, detector in detectors.items():\n",
    "        for data_name, dataset_c in datasets.items():\n",
    "            data_out = dataset_c(root=root, transform=trans, target_transform=ToUnknown(), download=True)\n",
    "            loader = DataLoader(data_in+data_out, batch_size=64, shuffle=False, worker_init_fn=seed_worker)\n",
    "            \n",
    "            scores = []\n",
    "            ys = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for x, y in loader:\n",
    "                    scores.append(detector(x.to(device)))\n",
    "                    ys.append(y.to(device))\n",
    "                    \n",
    "                scores = torch.cat(scores, dim=0).cpu()\n",
    "                ys = torch.cat(ys, dim=0).cpu()\n",
    "            \n",
    "            metrics = OODMetrics()\n",
    "            metrics.update(scores, ys)\n",
    "            r = metrics.compute()\n",
    "            r.update({\n",
    "                \"Method\": detector_name,\n",
    "                \"Dataset\": data_name\n",
    "            })\n",
    "            print(r)\n",
    "            results.append(r)\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f2ad2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_acc(net, att_idx=0, oe=False):\n",
    "    _ = net.eval()\n",
    "    \n",
    "    if oe:\n",
    "        target_trans = lambda y: torch.tensor(1)\n",
    "    else:\n",
    "         target_trans = lambda y: y[att_idx]\n",
    "\n",
    "    trans = Compose([Resize(size=(32, 32)), ToRGB(), ToTensor()])\n",
    "    data_in = GTSRB(root=root, train=False, transforms=trans, target_transform=target_trans)\n",
    "    loader = DataLoader(data_in, batch_size=64, shuffle=False, worker_init_fn=seed_worker)\n",
    "            \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            predicted = outputs.max(dim=1).indices\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return correct / total  \n",
    "\n",
    "def evaluate_accs(label_net, shape_net, color_net, shield_net):\n",
    "    r = {}\n",
    "    names = (\"Label\", \"Color\", \"Shape\",)\n",
    "    \n",
    "    for n, net in enumerate((label_net, color_net, shape_net)): \n",
    "        acc = evaluate_acc(net, n)\n",
    "        r[names[n]] = acc\n",
    "    \n",
    "    acc = evaluate_acc(shield_net, oe=True)\n",
    "    r[\"Sign\"] = acc\n",
    "    \n",
    "    return [r] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e1dfb17",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# TODO: add monkeypatching \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     shield_net \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_sign_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     shape_net \u001b[38;5;241m=\u001b[39m train_model(att_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_epochs\u001b[38;5;241m=\u001b[39mn_epochs)\n\u001b[1;32m     10\u001b[0m     color_net \u001b[38;5;241m=\u001b[39m train_model(att_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, n_epochs\u001b[38;5;241m=\u001b[39mn_epochs)\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36mtrain_sign_model\u001b[0;34m(n_epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m new_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_data_noatt \u001b[38;5;241m+\u001b[39m data_train_out, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, worker_init_fn\u001b[38;5;241m=\u001b[39mseed_worker)\n\u001b[1;32m     16\u001b[0m new_test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_data_noatt \u001b[38;5;241m+\u001b[39m data_test_out, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, worker_init_fn\u001b[38;5;241m=\u001b[39mseed_worker)\n\u001b[0;32m---> 18\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     21\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m SGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/share/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/share/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    246\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 247\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    251\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "results = []\n",
    "results_acc = []\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "for trial in range(10):\n",
    "    # TODO: add monkeypatching \n",
    "    shield_net = train_sign_model(n_epochs=n_epochs)\n",
    "    shape_net = train_model(att_index=2, num_classes=5, n_epochs=n_epochs)\n",
    "    color_net = train_model(att_index=1, num_classes=4, n_epochs=n_epochs)\n",
    "    label_net = train_model(att_index=0, num_classes=43, n_epochs=n_epochs)\n",
    "    \n",
    "    res = evaluate(label_net, shape_net, color_net, shield_net)\n",
    "    res_acc = evaluate_accs(label_net, shape_net, color_net, shield_net)\n",
    "    \n",
    "    for r in res:\n",
    "        r.update({\"Seed\": trial})\n",
    "        \n",
    "    for r in res_acc:\n",
    "        r.update({\"Seed\": trial})\n",
    "    \n",
    "    results += res\n",
    "    results_acc += res_acc\n",
    "    \n",
    "    del shield_net\n",
    "    del shape_net\n",
    "    del color_net\n",
    "    del label_net\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534bed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "result_df = pd.DataFrame(results)\n",
    "mean = (result_df.groupby(by=[\"Method\", \"Seed\"]).mean() * 100).groupby(\"Method\").agg([\"mean\", \"sem\"])[[\"AUROC\", \"AUPR-IN\", \"AUPR-OUT\", \"FPR95TPR\"]]\n",
    "mean\n",
    "print(mean.sort_values(by=(\"AUROC\", \"mean\")).sort_values(by=(\"AUROC\", \"mean\")).to_latex(float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6424f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "sem_auroc = result_df[result_df[\"Method\"] == \"Semantic\"].groupby(by=[\"Method\", \"Seed\"]).mean()[\"AUROC\"]\n",
    "sem_ensemble =  result_df[result_df[\"Method\"] == \"Ensemble\"].groupby(by=[\"Method\", \"Seed\"]).mean()[\"AUROC\"]\n",
    "\n",
    "print(ttest_ind(sem_auroc, sem_ensemble, equal_var=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((pd.DataFrame(results_acc) * 100).agg([\"mean\", \"sem\"]).to_latex(float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104d16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(result_df.groupby(by=[\"Method\", \"Seed\"]).mean() * 100).groupby(\"Method\").agg([\"mean\", \"sem\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535832b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results_acc).agg([\"mean\", \"sem\"])\n",
    "# dataset gives np.array([label, color, shape])\n",
    "\n",
    "# results_acc = evaluate_accs(label_net, shape_net, color_net, shield_net)\n",
    "# print(results_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6f7584",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e417e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ood_label(x):\n",
    "    if x == True:\n",
    "        return \"Normal\"\n",
    "    else:\n",
    "        return \"Anomaly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce252917",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = Compose([Resize(size=(32, 32)), ToRGB(), ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_ood.utils import OODMetrics, ToRGB, ToUnknown\n",
    "from pytorch_ood.dataset.img import Textures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm \n",
    "test_in_data = GTSRB(root=root, train=False, transforms=trans, target_transform=lambda y: y[0])\n",
    "\n",
    "detector = MaxSoftmax(label_net)\n",
    "\n",
    "sem_detector = SemanticDetector(\n",
    "    label_net, \n",
    "    shape_net, \n",
    "    color_net, \n",
    "    GTSRB(root=root).class_to_shape, \n",
    "    GTSRB(root=root).class_to_color, \n",
    "    sign_net=shield_net\n",
    ")\n",
    "\n",
    "scores = []\n",
    "my_scores = []\n",
    "ys = []\n",
    "xs = []\n",
    "ys_hat = []\n",
    "\n",
    "metrics = OODMetrics()\n",
    "\n",
    "datasets = (LSUNCrop, LSUNResize, Textures, TinyImageNetCrop, TinyImageNetResize)\n",
    "datasets = [c(root=root, transform=trans, target_transform=ToUnknown(), download=True) for c in datasets]\n",
    "loaders = [DataLoader(d, batch_size=128, worker_init_fn=seed_worker) for d in datasets]\n",
    "loaders.append( DataLoader(test_in_data, batch_size=128, worker_init_fn=seed_worker))\n",
    "\n",
    "with torch.no_grad():\n",
    "     for loader in loaders:\n",
    "        for x, y in tqdm(loader):\n",
    "            x = x.to(device)\n",
    "            scores.append(detector(x))\n",
    "            ys_hat.append(label_net(x).softmax(dim=1).max(dim=1).indices) \n",
    "            my_scores.append(sem_detector(x))\n",
    "\n",
    "            ys.append(y)\n",
    "            xs.append(x.cpu())\n",
    "\n",
    "\n",
    "scores = torch.cat(scores, dim=0).cpu()\n",
    "ys = torch.cat(ys, dim=0).cpu()\n",
    "ys_hat = torch.cat(ys_hat, dim=0).cpu()\n",
    "my_scores = torch.cat(my_scores, dim=0).cpu()\n",
    "xs = torch.cat(xs, dim=0).cpu()\n",
    "\n",
    "\n",
    "metrics = OODMetrics()\n",
    "metrics.update(my_scores, ys)\n",
    "print(metrics.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09904b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e8206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_ood.utils import is_unknown\n",
    "\n",
    "\n",
    "print(xs.shape)\n",
    "print(my_scores.shape)\n",
    "print(ys_hat.shape)\n",
    "print(ys.shape)\n",
    "print(scores.shape)\n",
    "\n",
    "print(is_known(ys).sum())\n",
    "print(is_unknown(ys).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6035b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "df_1 = DataFrame()\n",
    "df_1[\"Scores\"] = scores.cpu().numpy()\n",
    "df_1[\"Labels\"] = ys >= 0\n",
    "df_1[\"Labels\"] = df_1[\"Labels\"].apply(ood_label)\n",
    "df_1[\"Method\"] = \"Implicit\"\n",
    "\n",
    "sb.histplot(data=df_1, x=\"Scores\", hue=\"Labels\", common_norm=False, stat=\"probability\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efda13e3",
   "metadata": {},
   "source": [
    "# Examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53dd893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# custom_params = {\"axes.spines.right\": True, \"axes.spines.top\": True, \"axes.spines.bottom\": True, \"axes.spines.left\": True}\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "sb.set_theme(style=\"white\")\n",
    "\n",
    "sem_detector = SemanticDetector(\n",
    "    label_net, \n",
    "    shape_net, \n",
    "    color_net, \n",
    "    GTSRB(root=root).class_to_shape, \n",
    "    GTSRB(root=root).class_to_color, \n",
    "    sign_net=shield_net\n",
    ")\n",
    "\n",
    "dataset = GTSRB(root=root)\n",
    "\n",
    "top_values, top_indxs = (-scores[ys<0]).topk(50)\n",
    "\n",
    "# top_values, top_indxs = (- scores[ys<0]).topk(50)\n",
    "imgs = xs[top_indxs]\n",
    "\n",
    "for n, img in enumerate(imgs):\n",
    "    img_batch = img.unsqueeze(0).to(device)\n",
    "    \n",
    "    print(img_batch.shape)\n",
    "    with torch.no_grad():\n",
    "        l = label_net(img_batch)\n",
    "        s = shape_net(img_batch)\n",
    "        c = color_net(img_batch)\n",
    "        o = shield_net(img_batch)\n",
    "        \n",
    "    sign_detected = o.max(dim=1).indices.cpu()\n",
    "        \n",
    "    my_score = sem_detector(img_batch)[0]\n",
    "    \n",
    "    lindex = l.argmax(dim=1).item()\n",
    "    sindex = s.argmax(dim=1).item()\n",
    "    cindex = c.argmax(dim=1).item()\n",
    "    oindex = o.argmax(dim=1).item()\n",
    "    \n",
    "    lname = dataset.class_to_name[lindex -1]\n",
    "    sname = dataset.shape_to_name[sindex]\n",
    "    cname = dataset.color_to_name[cindex]\n",
    "    oname = \"Sign\" if oindex else \"NoSign\"\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(np.moveaxis(img.numpy(), 0, -1))\n",
    "    plt.suptitle(f\"'{lname.title()}' ({l.softmax(dim=1).max().item():.2%}) \\n {sname.title()} | {cname.title()} | {oname.title()}\" , fontsize=19)\n",
    "    plt.title(f\"Consistent: {'Yes' if abs(my_score) > 0.0 else 'No'}\", fontsize=19) # 'Yes' if my_score > 0.0 else 'No'\n",
    "    plt.tight_layout(pad=0.5)\n",
    "    plt.savefig(f\"img/prediction-example-{n}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c634ba4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sem_detector = SemanticDetector(\n",
    "    label_net, \n",
    "    shape_net, \n",
    "    color_net, \n",
    "    GTSRB(root=root).class_to_shape, \n",
    "    GTSRB(root=root).class_to_color, \n",
    "    sign_net=shield_net\n",
    ")\n",
    "\n",
    "top_values, top_indxs = (scores[ys>=0]).topk(50)\n",
    "\n",
    "for n, i in enumerate([i for i in top_indxs]):\n",
    "    img = xs[ys>=0][i]\n",
    "    img_batch = img.unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        l = label_net(img_batch)\n",
    "        s = shape_net(img_batch)\n",
    "        c = color_net(img_batch)\n",
    "        o = shield_net(img_batch)\n",
    "    \n",
    "    # my_score = detector(img_batch)[0]\n",
    "    my_score = my_scores[ys>=0][i]\n",
    "    # score = scores[ys>=0][i]\n",
    "    \n",
    "    lindex = l.argmax(dim=1).item()\n",
    "    sindex = s.argmax(dim=1).item()\n",
    "    cindex = c.argmax(dim=1).item()\n",
    "    oindex = o.argmax(dim=1).item()\n",
    "        \n",
    "    lname = dataset.class_to_name[lindex -1]\n",
    "    sname = dataset.shape_to_name[sindex]\n",
    "    cname = dataset.color_to_name[cindex]\n",
    "    oname = \"Sign\" if oindex == 1 else \"NoSign\"\n",
    "        \n",
    "    plt.imshow(np.moveaxis(img.numpy(), 0, -1))\n",
    "    plt.suptitle(f\"'{lname.title()}' ({l.softmax(dim=1).max().item():.2%}) \\n {sname.title()} | {cname.title()} | {oname}\", fontsize=19)\n",
    "    plt.title(f\"Consistent: {'Yes' if abs(my_score) > 0.0 else 'No'}\", fontsize=19) # 'Yes' if my_score > 0.0 else 'No'\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout(pad=0.5)\n",
    "    plt.savefig(f\"img/prediction-example-in-{n}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74822a7f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sem_detector = SemanticDetector(\n",
    "    label_net, \n",
    "    shape_net, \n",
    "    color_net, \n",
    "    GTSRB(root=root).class_to_shape, \n",
    "    GTSRB(root=root).class_to_color, \n",
    "    sign_net=shield_net\n",
    ")\n",
    "\n",
    "# in-distribution where prediction was not correct and was rejected \n",
    "index = (ys>=0) & (ys != ys_hat.cpu()) & (my_scores.abs() == 0.0)\n",
    "if index.sum().item() > 0:\n",
    "    top_values, top_indxs = (-scores[index]).topk(1)\n",
    "\n",
    "    for n, i in enumerate([i for i in top_indxs]):\n",
    "        img = xs[index][i]\n",
    "        img_batch = img.unsqueeze(0).to(device)\n",
    "\n",
    "        print(img_batch.shape)\n",
    "        with torch.no_grad():\n",
    "            l = label_net(img_batch)\n",
    "            s = shape_net(img_batch)\n",
    "            c = color_net(img_batch)\n",
    "            o = shield_net(img_batch)\n",
    "\n",
    "        my_score = sem_detector(img_batch)[0]\n",
    "\n",
    "        lindex = l.argmax(dim=1).item()\n",
    "        sindex = s.argmax(dim=1).item()\n",
    "        cindex = c.argmax(dim=1).item()\n",
    "\n",
    "        lname = dataset.class_to_name[lindex -1]\n",
    "        sname = dataset.shape_to_name[sindex]\n",
    "        cname = dataset.color_to_name[cindex]\n",
    "        oname = \"Sign\" if oindex == 1 else \"NoSign\"\n",
    "\n",
    "        plt.imshow(np.moveaxis(img.numpy(), 0, -1))\n",
    "        plt.suptitle(f\"'{lname.title()}' ({l.softmax(dim=1).max().item():.2%}) \\n {sname.title()} | {cname.title()} | {oname.title()}\", fontsize=19)\n",
    "        plt.title(f\"Consistent: {'Yes' if abs(my_score) > 0.0 else 'No'}\", fontsize=19) # 'Yes' if my_score > 0.0 else 'No'\n",
    "        plt.tight_layout(pad=0.5)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.savefig(f\"img/prediction-example-in-error-{n}.pdf\", bbox_inches=\"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3babd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# in-distribution where prediction was not correct and was accepted \n",
    "index = (ys>=0) & (ys == ys_hat.cpu()) & (my_scores.abs() >= 0.0)\n",
    "if index.sum().item() > 0:\n",
    "    top_values, top_indxs = (-scores[index]).topk(10)\n",
    "\n",
    "    for n, i in enumerate([i for i in top_indxs]):\n",
    "        img = xs[index][i]\n",
    "        img_batch = img.unsqueeze(0).to(device)\n",
    "\n",
    "        print(img_batch.shape)\n",
    "        with torch.no_grad():\n",
    "            l = label_net(img_batch)\n",
    "            s = shape_net(img_batch)\n",
    "            c = color_net(img_batch)\n",
    "            o = shield_net(img_batch)\n",
    "\n",
    "        my_score = sem_detector(img_batch)[0]\n",
    "\n",
    "        lindex = l.argmax(dim=1).item()\n",
    "        sindex = s.argmax(dim=1).item()\n",
    "        cindex = c.argmax(dim=1).item()\n",
    "\n",
    "        lname = dataset.class_to_name[lindex]\n",
    "        sname = dataset.shape_to_name[sindex]\n",
    "        cname = dataset.color_to_name[cindex]\n",
    "        oname = \"Sign\" if oindex == 1 else \"NoSign\"\n",
    "\n",
    "        plt.imshow(np.moveaxis(img.numpy(), 0, -1))\n",
    "        plt.suptitle(f\"'{lname.title()}' ({l.softmax(dim=1).max().item():.2%}) \\n {sname.title()} | {cname.title()} | {oname.title()}\")\n",
    "        plt.title(f\"Consistent: {'Yes' if abs(my_score) > 0.0 else 'No'}\") # 'Yes' if my_score > 0.0 else 'No'\n",
    "        plt.tight_layout(pad=0.5)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.savefig(f\"img/prediction-example-in-correct-{n}.pdf\", bbox_inches=\"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be656b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sb \n",
    "\n",
    "# ys_hat_anom = ys_hat.clone()\n",
    "# ys_hat_anom[my_scores > -0.99] = 44 \n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(20,20))\n",
    "# m = confusion_matrix(ys[ys >= 0], ys_hat_anom[ys >= 0])\n",
    "\n",
    "# for i in range(m.shape[0]):\n",
    "#     m[i,i] = 0\n",
    "    \n",
    "# disp = ConfusionMatrixDisplay(m, display_labels=list(dataset.class_to_name.values()) + [\"Anomaly\"])\n",
    "# disp.plot(ax=ax, xticks_rotation=\"vertical\", colorbar=False)\n",
    "\n",
    "# plt.tight_layout(pad=0)\n",
    "\n",
    "# plt.savefig(\"img/confusion.pdf\")\n",
    "# plt.savefig(\"img/confusion.jpg\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b85f0-9156-4c75-82a6-85b81f0a813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "msp = MaxSoftmax(label_net)\n",
    "semantic_detector = SemanticDetector(\n",
    "                label_net, \n",
    "                shape_net, \n",
    "                color_net, \n",
    "                GTSRB(root=root).class_to_shape, \n",
    "                GTSRB(root=root).class_to_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f076b8e-1f3c-48a7-97d7-ebb3a7acf5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_ood.utils import TensorBuffer\n",
    "\n",
    "data_in = GTSRB(root=root, train=False, transforms=trans, target_transform=lambda y: y[0])\n",
    "data_out = Textures(root=root, transform=trans, target_transform=ToUnknown(), download=True)\n",
    "\n",
    "loader = DataLoader(data_in + data_out, shuffle=False, batch_size=128)\n",
    "\n",
    "buffer = TensorBuffer()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in loader:\n",
    "        scores_msp = msp(x.to(device))\n",
    "        buffer.append(\"msp\", scores_msp)\n",
    "\n",
    "        scores_sem = semantic_detector(x.to(device))\n",
    "        buffer.append(\"sem\", scores_sem)\n",
    "\n",
    "        buffer.append(\"y\", y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
